{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Word Vectors with TensorFlow: Optimizer Selection\n",
    "### SGD with Momentum\n",
    "Patrick Coady (pcoady@alum.mit.edu)\n",
    "\n",
    "(*tune_sherlock1* and *tune_sherlock2* used RMSProp optimizer.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from wordvector import WordVector\n",
    "from windowmodel import WindowModel\n",
    "import docload\n",
    "from plot_util import plot_results\n",
    "\n",
    "import numpy as np\n",
    "import sklearn.utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "files = ['../data/adventures_of_sherlock_holmes.txt',\n",
    "        '../data/hound_of_the_baskervilles.txt',\n",
    "        '../data/sign_of_the_four.txt']\n",
    "word_array, dictionary, num_lines, num_words = docload.build_word_array(\n",
    "    files, vocab_size=50000, gutenberg=True)\n",
    "print('Document loaded and processed: {} lines, {} words.'\n",
    "      .format(num_lines, num_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x, y = WindowModel.build_training_set(word_array)\n",
    "\n",
    "# shuffle and split 10% validation data\n",
    "x_shuf, y_shuf = sklearn.utils.shuffle(x, y, random_state=0)\n",
    "split = round(x_shuf.shape[0]*0.9)\n",
    "x_val, y_val = (x_shuf[split:, :], y_shuf[split:, :])\n",
    "x_train, y_train = (x[:split, :], y[:split, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Rate and Momentum\n",
    "\n",
    "learn_rate = {0.0001, 0.001, 0.01}  \n",
    "momentum = {0.8, 0.9, 0.95}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results_list = []\n",
    "count = 0\n",
    "for learn_rate in [0.0001, 0.001, 0.01]:\n",
    "    for momentum in [0.8, 0.9, 0.95]: \n",
    "        print('{}) learn_rate = {}, momentum = {}'\n",
    "              .format(count, learn_rate, momentum))\n",
    "        count += 1\n",
    "        graph_params = {'batch_size': 32,\n",
    "                        'vocab_size': np.max(x)+1,\n",
    "                        'embed_size': 128,\n",
    "                        'hid_size': 128,\n",
    "                        'neg_samples': 64,\n",
    "                        'learn_rate': learn_rate,\n",
    "                        'momentum': momentum,\n",
    "                        'embed_noise': 1,\n",
    "                        'hid_noise': 0.3,\n",
    "                        'optimizer': 'Momentum'}  # name for model save\n",
    "        model = WindowModel(graph_params)\n",
    "        results = model.train(x_train, y_train, x_val, y_val, epochs=80, verbose=False)\n",
    "        results_list.append((graph_params, results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_results(results_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Larger Learning Rates\n",
    "\n",
    "**First round found best learn rate was 0.01, another round to check even larger learning rates**  \n",
    "\n",
    "learn_rate = {0.1, 1, 10}  \n",
    "momentum = {0.8, 0.9, 0.95}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_list2= []\n",
    "count = 0\n",
    "for learn_rate in [0.1, 1, 10]:\n",
    "    for momentum in [0.8, 0.9, 0.95]: \n",
    "        print('{}) learn_rate = {}, momentum = {}'\n",
    "              .format(count, learn_rate, momentum))\n",
    "        count += 1\n",
    "        graph_params = {'batch_size': 32,\n",
    "                        'vocab_size': np.max(x)+1,\n",
    "                        'embed_size': 128,\n",
    "                        'hid_size': 128,\n",
    "                        'neg_samples': 64,\n",
    "                        'learn_rate': learn_rate,\n",
    "                        'momentum': momentum,\n",
    "                        'embed_noise': 1,\n",
    "                        'hid_noise': 0.3,\n",
    "                        'optimizer': 'Momentum'}\n",
    "        model = WindowModel(graph_params)\n",
    "        results = model.train(x_train, y_train, x_val, y_val, epochs=80, verbose=False)\n",
    "        results_list2.append((graph_params, results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_results(results_list2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
